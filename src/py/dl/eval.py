
from __future__ import print_function
import numpy as np
import tensorflow as tf
import argparse
import importlib
import os
from datetime import datetime
import json
import glob
import itk
import sys
import csv
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
import itertools
from scipy import interp


print("Tensorflow version:", tf.__version__)

parser = argparse.ArgumentParser(description='Model evaluation', formatter_class=argparse.ArgumentDefaultsHelpFormatter)

parser.add_argument('--json_tf', type=str, help='JSON file generated by tfRecords.py. Used to evaluate the model.', required=True)
parser.add_argument('--json', type=str, help='JSON file with model description, created by train.py', required=True)
parser.add_argument('--ps_device', help='Process device', type=str, default='/cpu:0')
parser.add_argument('--w_device', help='Worker device', type=str, default='/cpu:0')

args = parser.parse_args()

json_model_name = args.json
json_tf_records = args.json_tf

ps_device = args.ps_device
w_device = args.w_device
class_names = []
with open(json_model_name, "r") as f:
  model_description = json.load(f)
  model_name = os.path.join(os.path.dirname(json_model_name), model_description["model"])
  neural_network = model_description["nn"]
  if("description" in model_description and "enumerate" in model_description["description"]):
    class_dict = model_description["description"][model_description["description"]["enumerate"]]["class"]
    class_obj = {}
    for key in class_dict:
      class_obj[class_dict[key]] = key
    class_names = class_obj.values()

print('json', json_model_name)
print('json_tf', json_tf_records)
print('model_name', model_name)
print('neural_network', neural_network)

print('ps_device', ps_device)
print('w_device', w_device)

nn = importlib.import_module("nn." + neural_network).NN()

graph = tf.Graph()

with graph.as_default():

  if(model_description["batch_size"]):
    batch_size = model_description["batch_size"]
  else: 
    batch_size = 1

  if(model_description["buffer_size"]):
    buffer_size = model_description["buffer_size"]
  else: 
    buffer_size = 100

  nn.set_data_description(json_filename=json_tf_records)
  iterator = nn.inputs(batch_size=batch_size,
    num_epochs=1, 
    buffer_size=buffer_size)

  data_tuple = iterator.get_next()

  y_conv = nn.inference(data_tuple=data_tuple, keep_prob=1.0, is_training=False, ps_device=ps_device, w_device=w_device)
  metrics_eval = nn.metrics(y_conv, data_tuple)
  y_conv = nn.predict(y_conv)
  summary_op = tf.summary.merge_all()

  with tf.Session() as sess:

    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])
    saver = tf.train.Saver()
    saver.restore(sess, model_name)

    summary_path = model_name + "-eval"
    summary_writer = tf.summary.FileWriter(summary_path, sess.graph)

    print("I am self aware!")

    sess.run([iterator.initializer])

    step = 0 

    y_pred_arr = []
    y_true_arr = []

    fpr_arr = []
    tpr_arr = []
    roc_auc_arr = []
    iou_arr = []

    while True:
      try:

        y_pred, data_t, summary, metrics = sess.run([y_conv, data_tuple, summary_op, metrics_eval])

        # output some data to the log files for tensorboard
        summary_writer.add_summary(summary, step)
        summary_writer.flush()

        metrics_str = '|'

        for metric in metrics:
          metrics_str += " %s = %.3f |" % (metric, metrics[metric][0])

        print(metrics_str)

        if(nn.prediction_type() == "class"):
          y_pred_arr.extend(np.argmax(np.array(y_pred), axis=1))
          y_true_arr.extend(np.reshape(data_t[1], -1).tolist())
        elif(nn.prediction_type() == "segmentation"):
          fpr, tpr, _ = roc_curve(np.array(data_t[1]).reshape(-1), np.array(y_pred).reshape(-1), pos_label=1)
          roc_auc = auc(fpr,tpr)

          fpr_arr.append(fpr)
          tpr_arr.append(tpr)
          roc_auc_arr.append(roc_auc)

          y_pred_flat = np.array(y_pred).reshape((len(y_pred), -1))
          labels_flat = np.array(data_t[1]).reshape((len(y_pred), -1))

          for i in range(len(y_pred)):
            intersection = 2.0 * np.sum(y_pred_flat[i] * labels_flat[i]) + 1e-7
            union = np.sum(y_pred_flat[i]) + np.sum(labels_flat[i]) + 1e-7
            iou_arr.append(intersection/union)

        step += 1

      except tf.errors.OutOfRangeError:
        break




def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
  """
  This function prints and plots the confusion matrix.
  Normalization can be applied by setting `normalize=True`.
  """
  if normalize:
      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
      print("Normalized confusion matrix")
  else:
      print('Confusion matrix, without normalization')

  print(cm)

  plt.imshow(cm, interpolation='nearest', cmap=cmap)
  plt.title(title)
  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks, classes, rotation=45)
  plt.yticks(tick_marks, classes)

  fmt = '.3f' if normalize else 'd'
  thresh = cm.max() / 2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
      plt.text(j, i, format(cm[i, j], fmt),
               horizontalalignment="center",
               color="white" if cm[i, j] > thresh else "black")

  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.tight_layout()

if(nn.prediction_type() == "class"):
  # Compute confusion matrix
  cnf_matrix = confusion_matrix(y_true_arr, y_pred_arr)
  np.set_printoptions(precision=3)

  # Plot non-normalized confusion matrix
  fig = plt.figure()
  plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')
  confusion_filename = os.path.splitext(json_tf_records)[0] + "_confusion.png"
  fig.savefig(confusion_filename)
  # Plot normalized confusion matrix
  fig2 = plt.figure()
  plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')

  norm_confusion_filename = os.path.splitext(json_tf_records)[0] + "_norm_confusion.png"
  fig2.savefig(norm_confusion_filename)

elif(nn.prediction_type() == "segmentation"):

  # First aggregate all false positive rates
  all_fpr = np.unique(np.concatenate([fpr for fpr in fpr_arr]))

  # Then interpolate all ROC curves at this points
  mean_tpr = np.zeros_like(all_fpr)
  for i in range(len(fpr_arr)):
      mean_tpr += interp(all_fpr, fpr_arr[i], tpr_arr[i])

  mean_tpr /= len(fpr_arr)

  roc_auc = auc(all_fpr, mean_tpr)

  roc_fig = plt.figure()
  lw = 1
  plt.plot(all_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
  plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('Receiver operating characteristic')
  plt.legend(loc="lower right")

  roc_filename = os.path.splitext(json_tf_records)[0] + "_roc.png"
  roc_fig.savefig(roc_filename)

  iou_obj = {}
  iou_obj["iou"] = iou_arr

  iou_json = os.path.splitext(json_tf_records)[0] + "_iou_arr.json"

  with open(iou_json, "w") as f:
    f.write(json.dumps(iou_obj))

  iou_fig_polar = plt.figure()
  ax = iou_fig_polar.add_subplot(111, projection='polar')
  theta = 2 * np.pi * np.arange(len(iou_arr))/len(iou_arr)
  colors = iou_arr
  ax.scatter(theta, iou_arr, c=colors, cmap='autumn', alpha=0.75)
  ax.set_rlim(0,1)
  plt.title('Intersection over union')
  locs, labels = plt.xticks()
  plt.xticks(locs, np.arange(0, len(iou_arr), round(len(iou_arr)/len(locs))))

  iou_polar_filename = os.path.splitext(json_tf_records)[0] + "_iou_polar.png"
  iou_fig_polar.savefig(iou_polar_filename)

  iou_fig = plt.figure()
  x_samples = np.arange(len(iou_arr))
  plt.scatter(x_samples, iou_arr, c=colors, cmap='autumn', alpha=0.75)
  plt.title('Intersection over union')
  iou_mean = np.mean(iou_arr)
  plt.plot(x_samples,[iou_mean]*len(iou_arr), label='Mean', linestyle='--')
  plt.text(len(iou_arr) + 2,iou_mean, '%.3f'%iou_mean)
  iou_filename = os.path.splitext(json_tf_records)[0] + "_iou.png"
  iou_fig.savefig(iou_filename)

